---
title: "Practical Assignment 2 - Web and Text Mining"
author: "João Pires, Vanessa Silva"
date: "30 de Abril de 2017"
output: html_document
---
<br /> 

This report follows the analysis of [IMDB](http://www.imdb.com) movies and their reviews, is the retrieval of relevant information on movies and the analysis of the reviews (and respective scores) assigned by users of the site to the movies.
For this we will use our knowledge regarding web and text mining.

*Web Mining* consists of extracting information from the content of the pages, their links, and users' browsing logs, using data mining tools. 
Thus, we can divide Web Mining into three variants: Web Content Mining; Web Structure Mining; And Web Usage Mining.

*Text Mining* consists of extracting useful information from a collection of documents.
Involves basic pre-processing/text mining operations, such as identification/extraction of representative features, and identification of complex patterns as, e.g. relationships between previously identified concepts.
Text Mining exploits techniques/methodologies from data mining, machine learning, information retrieval, and corpus-based computational linguistics. Where corpus is a collection of documents.


**The Goal**

To use web and text mining to extract and study important informations in the movies and their reviews, of IMDB website.


##Necessary Packages

```{r, eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
#Install the necessary packages
install.packages("rvest")

```


```{r, message=FALSE, warning=FALSE}
#Load the necessary packages
library(rvest)

```


##Tasks

Using the information available in the IMDB site we will accomplish a series of tasks below.


###Find basic information

First we will find basic information as web page, diretor, cast, etc. of a movie based on a query string of the title.

```{r}
#Store web url
url_IMBD <- "http://www.imdb.com/"

# Submit the form on imdb.com for a movie description
Searchform <- function(session, query, type) {
  form <- html_form(session)[[1]]
  form <- set_values(form, q = query, s = type)
 
  return(submit_form(session, form))
}

# Returns a list of the movies that match to the search string, by decreasing order of confidence
listMovies <- function(query) { ##esta query tem de ser dada pelo utilizador (ver como fazer isso)
  type <- "tt"
  
  sessionMovies <- html_session(url_IMBD)
  
  results <- Searchform(sessionMovies, query, type)
  
  ##Definir o que vamos usar como ordem de confiança: (usar Information Retrieval, como os exemplos abaixo (como nos slides))
  
  return(list(results %>% html_nodes(".result_text") %>% html_text(), results))
   
}


r <- listMovies("Lego")
results <- r[[2]]
##For each movie the basic information is returned as a list: 
#add an extra parameter that controls the maximum number of retrieved movies
listM <- head(r[[1]], n = 10)       #top 10

# Find basic information
findBasInf <- function(m) {
  
  #web page
  m %>% read_html()
  
  #director(s)
  m %>% read_html() %>% html_nodes(".summary_text+ .credit_summary_item .itemprop") %>% html_text()
  
  #cast
  m %>% read_html() %>% html_nodes("#titleCast .itemprop span") %>% html_text()    ##See full cast »????
  
  #description
  m %>% read_html() %>% html_nodes(".summary_text") %>% html_text()
  
  #original title
  m %>% read_html() %>% html_nodes(".originalTitle") %>% html_text()
  
  #runtime
  m %>% read_html() %>% html_nodes("#titleDetails time") %>% html_text()
  
  #renre
  m %>% read_html() %>% html_nodes(".subtext .itemprop") %>% html_text()
  
  #date
  m %>% read_html() %>% html_nodes(".subtext a~ .ghost+ a") %>% html_text()
  
  #rating
  m %>% read_html() %>% html_nodes("strong span") %>% html_text()
  
  #metascore
  m %>% read_html() %>% html_nodes(".score_favorable span") %>% html_text()
  
  ##...
  
}

#web page link
movieLink <- head((results %>% html_nodes(".result_text > a") %>% html_attr("href")), n = 10)
movieLink <- paste(url_IMBD, movieLink, sep='')
lapply(movieLink, findBasInf(x))       ##demora a executae!!!



##### Information Retrieval #############################
library(tm)
docs <- r
corpus<-Corpus(VectorSource(docs)) 
dtm <- DocumentTermMatrix(corpus) 

# Term frequency – inverse document frequency Scheme
tfidf<-weightTfIdf(dtm)
as.matrix(tfidf) 

# Term frequency Scheme 
tf<-weightTf(dtm)
as.matrix(tf)

# Boolean model 
boolean<-weightBin(dtm) 
as.matrix(boolean) 

# Measuring dissimilarity between documents 
mycosdist<-function(x,y) 1-x%*%y/(sqrt(x%*%x)*sqrt(y%*%y))
library(proxy)
proxy::dist(as.matrix(dtm),method=mycosdist) 
 proxy::dist(as.matrix(weightBin(dtm)),method=mycosdist)
 proxy::dist(as.matrix(weightTf(dtm)),method=mycosdist) 
 proxy::dist(as.matrix(weightTfIdf(dtm)),method=mycosdist) 
 
 # Ranking docs given a query
 cq<-Corpus(VectorSource("Lego"))   ##a nossa query
 dtmq<-DocumentTermMatrix(cq)
 qv<-NULL
 qv[colnames(dtm)]<-0 
  qv[colnames(dtmq)]<-1 
  dtmqd<-rbind(as.matrix(dtm),qv) 
proxy::dist(dtmqd,method=mycosdist) 

# Ranking docs given a query using Tf-Idf scheme
dict<-colnames(dtm) # fetch the vocabulary of the corpus 
dtmq<-DocumentTermMatrix(Corpus(VectorSource("Lego")),list(dictionary=dict))  ##nossa query
tfidfq<-as.matrix(dtmq)[1,][dict]*log(3/apply(as.matrix(weightBin(dtm)),
2,sum))[dict] 
tfidfd<-as.matrix(weightTfIdf(dtm)) 
mycosdist(tfidfq,tfidfd[1,])
mycosdist(tfidfq,tfidfd[2,]) 
mycosdist(tfidfq,tfidfd[3,]) 

####### End ###############################



```


###Obtain the information on all reviews from a movie

###Model to predict the grade

####Build a data set for learning

####Try a few prediction models and draw conclusions

###Summarise the reviews of a movie